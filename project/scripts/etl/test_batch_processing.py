#!/usr/bin/env python3
"""
Script de Teste para Batch Processing
====================================

Script para testar e validar o sistema de batch processing
implementado para otimizar a coleta de fixtures.

Autor: ETL Engineer
Data: 17 de Janeiro de 2025
Task: 3.1 - Teste do Batch Processing
"""

import argparse
import sys
import os
import time
from datetime import datetime

# Adiciona o diretÃ³rio pai ao path para importar mÃ³dulos
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from etl.batch_collector import BatchCollector, create_batch_collector
from etl.config import ETLConfig
from test_config import setup_test_env

def test_single_batch(collector: BatchCollector, batch_size: int = 10):
    """Testa processamento de um Ãºnico lote"""
    print(f"\nğŸ§ª Testando lote Ãºnico com {batch_size} fixtures")
    
    # ObtÃ©m fixtures para teste
    fixture_ids = collector.get_fixtures_for_batch(batch_size)
    
    if not fixture_ids:
        print("âŒ Nenhuma fixture encontrada para teste")
        return False
    
    print(f"ğŸ“‹ Fixtures selecionadas: {fixture_ids[:5]}...")
    
    # Processa lote
    start_time = time.time()
    result = collector.process_batch(fixture_ids, includes=['statistics', 'events'])
    duration = time.time() - start_time
    
    # Salva resultados
    if result.successful_fixtures:
        collector.save_batch_results(result)
    
    # RelatÃ³rio
    print(f"âœ… Lote processado:")
    print(f"   ğŸ“Š Fixtures processadas: {len(result.fixture_ids)}")
    print(f"   âœ… Sucessos: {len(result.successful_fixtures)}")
    print(f"   âŒ Falhas: {len(result.failed_fixtures)}")
    print(f"   ğŸŒ Chamadas API: {result.api_calls_made}")
    print(f"   â±ï¸  DuraÃ§Ã£o: {duration:.2f}s")
    print(f"   ğŸš€ Taxa: {len(result.fixture_ids)/duration:.1f} fixtures/s")
    
    if result.errors:
        print(f"   âš ï¸  Erros: {len(result.errors)}")
        for error in result.errors[:3]:  # Mostra apenas os primeiros 3
            print(f"      â€¢ {error}")
    
    return len(result.successful_fixtures) > 0

def test_chunk_batch(collector: BatchCollector, league_id: int, season_id: int, batch_size: int = 50):
    """Testa processamento de chunk usando batch processing"""
    print(f"\nğŸ§ª Testando chunk {league_id}/{season_id} com batch processing")
    
    chunk_info = {
        'league_id': league_id,
        'season_id': season_id
    }
    
    # Processa chunk
    start_time = time.time()
    stats = collector.process_chunk_batch(chunk_info, batch_size)
    duration = time.time() - start_time
    
    # RelatÃ³rio
    print(f"âœ… Chunk processado:")
    print(f"   ğŸ“Š Fixtures processadas: {stats['processed']}")
    print(f"   âœ… Sucessos: {stats['successful']}")
    print(f"   âŒ Falhas: {stats['failed']}")
    print(f"   ğŸŒ Chamadas API: {stats['api_calls']}")
    print(f"   â±ï¸  DuraÃ§Ã£o: {duration:.2f}s")
    
    if stats['processed'] > 0:
        print(f"   ğŸš€ Taxa: {stats['processed']/duration:.1f} fixtures/s")
        print(f"   ğŸ“ˆ Taxa de sucesso: {stats['successful']/stats['processed']*100:.1f}%")
        print(f"   ğŸ¯ EficiÃªncia API: {stats['processed']/stats['api_calls']:.1f} fixtures/chamada")
    
    return stats['successful'] > 0

def compare_performance(collector: BatchCollector, fixture_count: int = 20):
    """Compara performance entre mÃ©todo individual e batch"""
    print(f"\nğŸ“Š ComparaÃ§Ã£o de Performance ({fixture_count} fixtures)")
    
    # ObtÃ©m fixtures para teste
    fixture_ids = collector.get_fixtures_for_batch(fixture_count)
    
    if len(fixture_ids) < fixture_count:
        print(f"âš ï¸  Apenas {len(fixture_ids)} fixtures disponÃ­veis")
        fixture_count = len(fixture_ids)
        fixture_ids = fixture_ids[:fixture_count]
    
    print(f"ğŸ“‹ Testando com {fixture_count} fixtures: {fixture_ids[:5]}...")
    
    # Teste 1: Batch Processing
    print("\nğŸ”„ Teste 1: Batch Processing")
    start_time = time.time()
    batch_result = collector.process_batch(fixture_ids, includes=['statistics'])
    batch_duration = time.time() - start_time
    
    print(f"   â±ï¸  DuraÃ§Ã£o: {batch_duration:.2f}s")
    print(f"   ğŸŒ Chamadas API: {batch_result.api_calls_made}")
    print(f"   ğŸš€ Taxa: {len(fixture_ids)/batch_duration:.1f} fixtures/s")
    print(f"   ğŸ“ˆ EficiÃªncia: {len(fixture_ids)/batch_result.api_calls_made:.1f} fixtures/chamada")
    
    # Teste 2: SimulaÃ§Ã£o de chamadas individuais
    print("\nğŸ”„ Teste 2: SimulaÃ§Ã£o de Chamadas Individuais")
    individual_start = time.time()
    individual_calls = len(fixture_ids)  # Uma chamada por fixture
    individual_duration = individual_start - individual_start + (len(fixture_ids) * 0.1)  # SimulaÃ§Ã£o
    
    print(f"   â±ï¸  DuraÃ§Ã£o estimada: {individual_duration:.2f}s")
    print(f"   ğŸŒ Chamadas API: {individual_calls}")
    print(f"   ğŸš€ Taxa estimada: {len(fixture_ids)/individual_duration:.1f} fixtures/s")
    print(f"   ğŸ“ˆ EficiÃªncia: {len(fixture_ids)/individual_calls:.1f} fixtures/chamada")
    
    # ComparaÃ§Ã£o
    print(f"\nğŸ“ˆ ComparaÃ§Ã£o:")
    speedup = individual_duration / batch_duration if batch_duration > 0 else 0
    api_reduction = (individual_calls - batch_result.api_calls_made) / individual_calls * 100
    
    print(f"   ğŸš€ AceleraÃ§Ã£o: {speedup:.1f}x mais rÃ¡pido")
    print(f"   ğŸŒ ReduÃ§Ã£o de chamadas API: {api_reduction:.1f}%")
    print(f"   â±ï¸  Economia de tempo: {individual_duration - batch_duration:.2f}s")
    
    return {
        'batch_duration': batch_duration,
        'individual_duration': individual_duration,
        'speedup': speedup,
        'api_reduction': api_reduction
    }

def main():
    """FunÃ§Ã£o principal"""
    parser = argparse.ArgumentParser(
        description='Testa sistema de batch processing para ETL Sportmonks',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Exemplos de uso:

  # Teste bÃ¡sico com 10 fixtures
  python test_batch_processing.py --test single --batch-size 10

  # Teste de chunk especÃ­fico
  python test_batch_processing.py --test chunk --league-id 2451 --season-id 23026

  # ComparaÃ§Ã£o de performance
  python test_batch_processing.py --test compare --fixture-count 50

  # Teste completo
  python test_batch_processing.py --test all
        """
    )
    
    parser.add_argument(
        '--test',
        choices=['single', 'chunk', 'compare', 'all'],
        default='single',
        help='Tipo de teste a executar'
    )
    
    parser.add_argument(
        '--batch-size',
        type=int,
        default=10,
        help='Tamanho do lote para teste (padrÃ£o: 10)'
    )
    
    parser.add_argument(
        '--league-id',
        type=int,
        help='ID da liga para teste de chunk'
    )
    
    parser.add_argument(
        '--season-id',
        type=int,
        help='ID da temporada para teste de chunk'
    )
    
    parser.add_argument(
        '--fixture-count',
        type=int,
        default=20,
        help='NÃºmero de fixtures para comparaÃ§Ã£o (padrÃ£o: 20)'
    )
    
    parser.add_argument(
        '--verbose',
        action='store_true',
        help='Log detalhado'
    )
    
    args = parser.parse_args()
    
    # Configura ambiente de teste
    setup_test_env()
    
    # Valida configuraÃ§Ãµes
    if not ETLConfig.validate():
        print("âš ï¸  ConfiguraÃ§Ãµes de teste detectadas. Para teste real, configure as variÃ¡veis de ambiente.")
        print("   SPORTMONKS_API_TOKEN=seu_token_real")
        print("   SUPABASE_CONNECTION_STRING=sua_string_conexao_real")
        sys.exit(1)
    
    # Configura logging
    if args.verbose:
        import logging
        logging.getLogger().setLevel(logging.DEBUG)
    
    # ConfiguraÃ§Ã£o
    config = ETLConfig.get_connection_params()
    
    print("ğŸš€ Iniciando Testes de Batch Processing")
    print(f"ğŸ“… Data/Hora: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"ğŸ”§ ConfiguraÃ§Ã£o:")
    print(f"   Batch Size: {args.batch_size}")
    print(f"   Teste: {args.test}")
    print("-" * 50)
    
    try:
        # Cria coletor
        collector = create_batch_collector(
            config['api_key'],
            config['connection_string']
        )
        
        success_count = 0
        total_tests = 0
        
        # Executa testes baseado no tipo
        if args.test in ['single', 'all']:
            total_tests += 1
            if test_single_batch(collector, args.batch_size):
                success_count += 1
        
        if args.test in ['chunk', 'all']:
            total_tests += 1
            league_id = args.league_id or 2451  # Premier League
            season_id = args.season_id or 23026  # Temporada atual
            
            if test_chunk_batch(collector, league_id, season_id, args.batch_size):
                success_count += 1
        
        if args.test in ['compare', 'all']:
            total_tests += 1
            results = compare_performance(collector, args.fixture_count)
            if results['speedup'] > 1:
                success_count += 1
        
        # RelatÃ³rio final
        print("\n" + "=" * 50)
        print("ğŸ“Š RelatÃ³rio Final dos Testes")
        print("=" * 50)
        print(f"âœ… Testes bem-sucedidos: {success_count}/{total_tests}")
        print(f"ğŸ“ˆ Taxa de sucesso: {success_count/total_tests*100:.1f}%")
        
        if success_count == total_tests:
            print("ğŸ‰ Todos os testes passaram! Batch processing estÃ¡ funcionando corretamente.")
        else:
            print("âš ï¸  Alguns testes falharam. Verifique os logs para detalhes.")
        
        print("\nğŸ’¡ PrÃ³ximos passos:")
        print("   â€¢ Integrar batch processing no sistema principal")
        print("   â€¢ Implementar cache Redis (Task 3.2)")
        print("   â€¢ Otimizar rate limiting (Task 3.3)")
    
    except KeyboardInterrupt:
        print("\nâ¹ï¸  Testes interrompidos pelo usuÃ¡rio")
        sys.exit(0)
    except Exception as e:
        print(f"\nğŸ’¥ Erro fatal: {e}")
        sys.exit(1)
    finally:
        if 'collector' in locals():
            collector.disconnect()

if __name__ == "__main__":
    main()
